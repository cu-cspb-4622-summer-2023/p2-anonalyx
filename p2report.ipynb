{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-15T01:53:30.207565Z",
     "start_time": "2023-08-15T01:53:30.205778Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpipeline\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Pipeline\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pyplot \u001B[38;5;28;01mas\u001B[39;00m plt\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layers\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project Topic\n",
    "\n",
    "\n",
    "Explanation: Sentiment analysis is one of the crowning achievements of recent advances in machine learning. In its most naive form, sentiment analysis is a simple binary classification with two possible label outputs, calculated as a function of an input string. In the case that we will explore, the input string is a single movie review, and the corpus of documents is all of the full text movie reviews in the dataset. The basic strategy for sentiment analysis includes drawing inferences and making predictions based on the relative importance and prominence of a word within a sequence or given document against the corpus of all documents. In this report, we will be utilizing unsupervised, supervised, and deep learning methods to estimate sentiment analysis on a corpus of documents.\n",
    "\n",
    "Our strategy in this report will be to use the tfidf vectorizer from sklearn to create a vocabulary and sparse matrix for each document. Then we will build a supervised model with the Random Forest Classifier, using Randomized Search CV to tune the hyperparameters for both the vectorizer and the Random Forest Classifier as a benchmark. Finally, we will build a multilayer neural network with Keras, that uses our sparse matrix and vocabulary as input, and determines the appropriate label as an output.\n",
    "Motivation: My motivation is to wield the full spectrum of techniques across unsupervised, supervised, and deep learning that we have learned this semester in a cohesive end-to-end model, and to compare the results between these approaches."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data\n",
    "Source: Kaggle.com \"Bag of Words Meets Bags of Popcorn\" https://www.kaggle.com/competitions/word2vec-nlp-tutorial/data\n",
    "Description: The Bag of Words Meets Bags of Popcorn Dataset is the dataset used in an NLP tutorial on Kaggle.com. I have not previously viewed or completed this tutorial and do not intend to use the techniques and methods described in the tutorial in the completion of my project.\n",
    "\n",
    "The dataset includes three features \"id\" (categorical), \"sentiment\" (numerical), and \"review\" (categorical). There are 75,000 total observations (25,000 train observations, and 50,000 test observations) in the dataset. The train observations are labeled with sentiment 1.0 or 0.0, where a review was scored either >= 7 or < 7 respectively. There are no null values, in the train dataset.\n",
    "\n",
    "Given we do not have the labels for the test dataset, we will have to use a portion of the train data set for validation purposes, and we will not be able to fully evaluate the efficacy of our model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class RecommenderSystem:\n",
    "    def __init__(self, train, test):\n",
    "        self.ntrain = len(train)\n",
    "        self.ntest = len(test)\n",
    "        self.X = pd.concat([trainLabeled, test]).dropna(how='all')\n",
    "        self.test = np.asarray(self.X[self.ntrain:])\n",
    "\n",
    "    def vectorize(self, max_features):\n",
    "        vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "        Xtfidf = vectorizer.fit_transform(self.X['review'])\n",
    "        self.vocab = np.asarray(vectorizer.get_feature_names_out())\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(Xtfidf[:self.ntrain], np.asarray(self.X[:self.ntrain]['sentiment']))\n",
    "        return self\n",
    "    def fit(self, model):\n",
    "        self.model = model\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self):\n",
    "        self.yp = self.model.predict(self.X_test)\n",
    "        return self\n",
    "\n",
    "    def score(self):\n",
    "        return accuracy_score(self.y_test, self.yp)\n",
    "\n",
    "trainLabeled = pd.read_csv('./data/labeledTrainData.tsv', sep='\\t', header=0, quoting=3).set_index('id')\n",
    "test = pd.read_csv('./data/unlabeledTrainData.tsv', sep='\\t', header=0, quoting=3).set_index('id').drop('Unnamed: 2',axis=1)\n",
    "\n",
    "rm = RecommenderSystem(trainLabeled, test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning and EDA\n",
    "Explanation of how and why cleaning is performed:\n",
    "\n",
    "The cleaning that we need to do on this dataset is limited to the cleaning and parsing of strings, and resulting transformation into a sparse matrix for input into subsequent models. Looking at the reviews, we can see that the text is ascii, however, we will need to make sure that all of the words are lowercase, that all punctuation and special characters are removed, that all stop words are eliminated.\n",
    "\n",
    "The sklearn vectorizers will perform these transformations for us automatically when we pass our full dataset to the fit_transform function. TFIDF does not remove stop words, however, by setting max_features at any reasonable threshold, we will eliminate those tokens which are most common to all documents in the corpus and thus, least meaningful, implicitly eliminating the stop words for us.\n",
    "\n",
    "To transform the data into a sparse matrix, we are going to use a textvectorizer that calculates the term frequency, inverse document frequency (TFIDF) of each word in each document. This will produce a vocabulary for us that consists of a vector of length (max_features) where each element of the vector corresponds with a word in our vocabulary. Our vocabulary will be derived from the full set of all reviews (training and test). As we learned in previous assignments, we can derive our vocabulary from the entire corpus of documents, without biasing our model. This is because our TFIDF vectorizer is not aware of the labels associated with each observation, and is merely deriving the relationship between words and documents in the corpus.\n",
    "\n",
    "We will chose TFIDF over a basic CountVectorizer, given the basic objective of sentiment analysis is identifying the magnitude and direction of each word as it relates to the cumulative sentiment of the document. A simple word count would be too likely to include words that are frequently used but have low meaning.\n",
    "\n",
    "Visualizations: Due to the high dimensionality of the dataset, I will not be able to create meaningful visual graphs of the data, and will instead rely on data tables.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 124273 words in the corpus\n"
     ]
    }
   ],
   "source": [
    "#We can call vectorize with parameter None, this will set max_features = None, and produce a sparse matrix with all words in the corpus included in the vocabulary\n",
    "rm.vectorize(None)\n",
    "print(f\"there are {len(rm.vocab)} words in the corpus\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['afterwords', 'gadgets', 'gadget', 'murky', 'faults',\n       'lighthearted', 'fascination', 'wished', 'miscast', 'broderick',\n       'interested', 'admittedly', 'college', 'considered', 'became',\n       'missing', 'exists', 'besides', 'reasonable', 'crazy', 'smart',\n       'legacy', 'went', 'cartoon', 'charming', 'might', 'treatment',\n       'charm', 'deserve', 'enjoyable', 'live', 'wacky', 'attitude',\n       'thing', 'before', 'seeing', 'seriously', 'interesting', 'back',\n       'enough', 'grade', 'saw', 'role', 'were', 'naturally', 'used',\n       'while', 'far', 'perhaps', 'rather', 'funny', 'around', 'been',\n       'liked', 'action', 'itself', 'original', 'fun', 'plot', 'took',\n       'doesn', 'even', 'close', 'didn', 'earth', 'too', 'picture',\n       'motion', 'much', 'seem', 'story', 'effects', 'though', 'its',\n       'what', 'never', 'being', 'version', 'great', 'very', 'be', 'had',\n       'have', 'as', 'on', 'only', 'if', 'made', 'that', 'movie', 'like',\n       'br', 'about', 'of', 'it', 'when', 'which', 'film', 'part', 'or',\n       'make', 'in', 'was', 'who', 'get', 'just', 'and', 'to', 'the',\n       'all', 'with'], dtype=object)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Demonstration that we can recover the original text from each review by finding the inner product of the tfidf transformed X_train set and the vocabulary\n",
    "nzi = np.nonzero(rm.X_train[0].reshape((rm.X_train.shape[1],1)))\n",
    "unique_words_in_first_doc = rm.vocab[nzi[0]]\n",
    "unique_words_in_first_doc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model building/ Model Choice\n",
    "\n",
    "Our model building will consist of 2 independent models. The first will be a supervised learning model with a Random Forest Classifier. The second will be a deep learning model with a Multilayer Neural Network. We choose these two models as a demonstration that unsupervised learning on a dataset to reduce the number of dimensions that each model is fit on, is effective for both a supervised and deep learning approach. In fact a combination of all of these approaches is best for truly understanding and evaluating such a large dataset, with as many features as ours has. The choice of RandomForestClassifier is obvious for data classification given it is robust to high dimensionality data sets, the interpretability of the model, and the nonlinearity that aligns well with our nonlinear corpus.\n",
    "\n",
    "In the first phase, we will want to tune the hyperparameters for both our TfidfVectorizer and our RandomForestClassifier. The relevant parameters to tune for the Tfidf are the max_features, which indicates the total numbers of words included in our vocabulary ordered by their rank, and for the RandomForestClassifier, we will choose number of estimators (i.e., the number of decision trees in the forest) and the max depth which is the longest path from root to leaf within the tree.\n",
    "\n",
    "We will use RandomizedSearchCV to select 1/5 folds of data for validation and the other 4/5 for training. Then it will randomly select combinations of the hyperparameters as specified in our hyper parameter grid. We choose RandomSearchCV because an exhaustive GridSearchCV would be too computationally intensive given the size of the dataset and the time taken to fit a randomforestclassifier with >100 estimators. Thus, we can specify the max number of iterations before halting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n                ('est', RandomForestClassifier())])",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n                (&#x27;est&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n                (&#x27;est&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", TfidfVectorizer()),\n",
    "        (\"est\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomizedSearchCV(estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n                                             ('est',\n                                              RandomForestClassifier())]),\n                   n_iter=25, n_jobs=-1,\n                   param_distributions={'est__max_depth': (5, 15, 30),\n                                        'est__n_estimators': (100, 200, 300),\n                                        'vectorizer__max_features': (5000,\n                                                                     10000,\n                                                                     15000,\n                                                                     20000)},\n                   verbose=1)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n                                             (&#x27;est&#x27;,\n                                              RandomForestClassifier())]),\n                   n_iter=25, n_jobs=-1,\n                   param_distributions={&#x27;est__max_depth&#x27;: (5, 15, 30),\n                                        &#x27;est__n_estimators&#x27;: (100, 200, 300),\n                                        &#x27;vectorizer__max_features&#x27;: (5000,\n                                                                     10000,\n                                                                     15000,\n                                                                     20000)},\n                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n                                             (&#x27;est&#x27;,\n                                              RandomForestClassifier())]),\n                   n_iter=25, n_jobs=-1,\n                   param_distributions={&#x27;est__max_depth&#x27;: (5, 15, 30),\n                                        &#x27;est__n_estimators&#x27;: (100, 200, 300),\n                                        &#x27;vectorizer__max_features&#x27;: (5000,\n                                                                     10000,\n                                                                     15000,\n                                                                     20000)},\n                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n                (&#x27;est&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_grid = {\n",
    "    \"vectorizer__max_features\": (5000, 10000,15000,20000),\n",
    "    \"est__n_estimators\": ( 100, 200, 300),\n",
    "    \"est__max_depth\": (5, 15, 30),\n",
    "}\n",
    "rscv = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=parameter_grid,\n",
    "    n_iter=25,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "rscv.fit(trainLabeled.review, trainLabeled.sentiment)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rscv.cv_results_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we've completed our RandomizedSearchCV, we can evaluate the dataframe and look at the mean fit time and mean fit score for each set of hyperparameters tested on our 5-fold cross validation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       77.726650      0.694767         4.772267        0.121720   \n1       22.653149      1.005098         3.995637        0.987942   \n2       25.474395      1.263212         3.148176        0.643088   \n3       18.812101      0.286187         2.982726        0.119216   \n4       19.829720      1.744731         4.132402        0.853231   \n5       76.539661      1.091985         2.816238        0.083034   \n6       57.310531      4.774374         2.995095        0.410694   \n7      108.084574      0.442638         2.714026        0.085175   \n8       74.050636      1.998914         2.662436        0.317836   \n9       32.544724      0.656039         2.408186        0.249703   \n10      42.586154      0.649467         3.254841        0.681108   \n11      18.124797      1.233893         2.507843        0.421389   \n12      14.714802      1.141484         3.029146        0.375274   \n13      21.462008      0.330464         2.636087        0.452202   \n14     107.812964      1.901465         3.988276        0.963980   \n15     120.473368      3.454322         3.530580        0.212565   \n16      76.711362      1.045535         3.617515        0.506694   \n17      16.442223      2.119059         2.814499        0.599392   \n18      17.500026      3.173084         2.306454        0.327360   \n19      32.371416      0.477811         1.933712        0.091638   \n20      39.291709      1.279783         2.875189        0.148272   \n21      17.072113      0.267165         2.538087        0.155290   \n22     104.207083      1.551340         4.066934        0.365598   \n23      38.174738      2.601185         3.336710        0.518688   \n24      34.907445      6.594209         1.966354        0.588720   \n\n   param_vectorizer__max_features param_est__n_estimators  \\\n0                           15000                     200   \n1                           15000                     300   \n2                            5000                     100   \n3                           20000                     300   \n4                            5000                     200   \n5                           20000                     200   \n6                            5000                     300   \n7                            5000                     300   \n8                            5000                     200   \n9                           20000                     100   \n10                          15000                     300   \n11                          20000                     100   \n12                          15000                     200   \n13                          15000                     100   \n14                          20000                     300   \n15                          10000                     300   \n16                          10000                     200   \n17                          20000                     200   \n18                          10000                     200   \n19                          10000                     100   \n20                          10000                     300   \n21                          10000                     300   \n22                          15000                     300   \n23                          10000                     200   \n24                          20000                     300   \n\n   param_est__max_depth                                             params  \\\n0                    30  {'vectorizer__max_features': 15000, 'est__n_es...   \n1                     5  {'vectorizer__max_features': 15000, 'est__n_es...   \n2                    15  {'vectorizer__max_features': 5000, 'est__n_est...   \n3                     5  {'vectorizer__max_features': 20000, 'est__n_es...   \n4                     5  {'vectorizer__max_features': 5000, 'est__n_est...   \n5                    30  {'vectorizer__max_features': 20000, 'est__n_es...   \n6                    15  {'vectorizer__max_features': 5000, 'est__n_est...   \n7                    30  {'vectorizer__max_features': 5000, 'est__n_est...   \n8                    30  {'vectorizer__max_features': 5000, 'est__n_est...   \n9                    30  {'vectorizer__max_features': 20000, 'est__n_es...   \n10                   15  {'vectorizer__max_features': 15000, 'est__n_es...   \n11                   15  {'vectorizer__max_features': 20000, 'est__n_es...   \n12                    5  {'vectorizer__max_features': 15000, 'est__n_es...   \n13                   15  {'vectorizer__max_features': 15000, 'est__n_es...   \n14                   30  {'vectorizer__max_features': 20000, 'est__n_es...   \n15                   30  {'vectorizer__max_features': 10000, 'est__n_es...   \n16                   30  {'vectorizer__max_features': 10000, 'est__n_es...   \n17                    5  {'vectorizer__max_features': 20000, 'est__n_es...   \n18                    5  {'vectorizer__max_features': 10000, 'est__n_es...   \n19                   30  {'vectorizer__max_features': 10000, 'est__n_es...   \n20                   15  {'vectorizer__max_features': 10000, 'est__n_es...   \n21                    5  {'vectorizer__max_features': 10000, 'est__n_es...   \n22                   30  {'vectorizer__max_features': 15000, 'est__n_es...   \n23                   15  {'vectorizer__max_features': 10000, 'est__n_es...   \n24                   15  {'vectorizer__max_features': 20000, 'est__n_es...   \n\n    split0_test_score  split1_test_score  split2_test_score  \\\n0              0.8374             0.8426             0.8420   \n1              0.8152             0.8210             0.8146   \n2              0.8196             0.8266             0.8300   \n3              0.8198             0.8208             0.8190   \n4              0.8058             0.8192             0.8098   \n5              0.8356             0.8424             0.8380   \n6              0.8284             0.8336             0.8258   \n7              0.8304             0.8412             0.8390   \n8              0.8328             0.8424             0.8352   \n9              0.8270             0.8332             0.8330   \n10             0.8290             0.8344             0.8318   \n11             0.8240             0.8354             0.8214   \n12             0.8114             0.8114             0.8214   \n13             0.8262             0.8334             0.8240   \n14             0.8354             0.8440             0.8394   \n15             0.8362             0.8444             0.8420   \n16             0.8312             0.8386             0.8376   \n17             0.8144             0.8208             0.8112   \n18             0.8144             0.8210             0.8148   \n19             0.8272             0.8334             0.8366   \n20             0.8266             0.8364             0.8318   \n21             0.8104             0.8206             0.8140   \n22             0.8382             0.8420             0.8420   \n23             0.8244             0.8322             0.8274   \n24             0.8302             0.8410             0.8300   \n\n    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n0              0.8514             0.8458          0.84384        0.004634   \n1              0.8200             0.8178          0.81772        0.002532   \n2              0.8324             0.8292          0.82756        0.004390   \n3              0.8304             0.8266          0.82332        0.004434   \n4              0.8188             0.8202          0.81476        0.005840   \n5              0.8470             0.8416          0.84092        0.003910   \n6              0.8388             0.8342          0.83216        0.004581   \n7              0.8476             0.8400          0.83964        0.005508   \n8              0.8464             0.8426          0.83988        0.005065   \n9              0.8448             0.8396          0.83552        0.006117   \n10             0.8394             0.8398          0.83488        0.004217   \n11             0.8422             0.8264          0.82988        0.007757   \n12             0.8238             0.8262          0.81884        0.006262   \n13             0.8384             0.8290          0.83020        0.005164   \n14             0.8512             0.8468          0.84336        0.005527   \n15             0.8468             0.8434          0.84256        0.003545   \n16             0.8462             0.8480          0.84032        0.006117   \n17             0.8254             0.8182          0.81800        0.004936   \n18             0.8248             0.8190          0.81880        0.003905   \n19             0.8404             0.8290          0.83332        0.004838   \n20             0.8424             0.8424          0.83592        0.006133   \n21             0.8228             0.8184          0.81724        0.004491   \n22             0.8518             0.8452          0.84384        0.004556   \n23             0.8424             0.8326          0.83180        0.006120   \n24             0.8440             0.8382          0.83668        0.005677   \n\n    rank_test_score  \n0                 1  \n1                23  \n2                18  \n3                19  \n4                25  \n5                 5  \n6                14  \n7                 8  \n8                 7  \n9                11  \n10               12  \n11               17  \n12               20  \n13               16  \n14                3  \n15                4  \n16                6  \n17               22  \n18               21  \n19               13  \n20               10  \n21               24  \n22                1  \n23               15  \n24                9  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_vectorizer__max_features</th>\n      <th>param_est__n_estimators</th>\n      <th>param_est__max_depth</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>77.726650</td>\n      <td>0.694767</td>\n      <td>4.772267</td>\n      <td>0.121720</td>\n      <td>15000</td>\n      <td>200</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8374</td>\n      <td>0.8426</td>\n      <td>0.8420</td>\n      <td>0.8514</td>\n      <td>0.8458</td>\n      <td>0.84384</td>\n      <td>0.004634</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22.653149</td>\n      <td>1.005098</td>\n      <td>3.995637</td>\n      <td>0.987942</td>\n      <td>15000</td>\n      <td>300</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8152</td>\n      <td>0.8210</td>\n      <td>0.8146</td>\n      <td>0.8200</td>\n      <td>0.8178</td>\n      <td>0.81772</td>\n      <td>0.002532</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25.474395</td>\n      <td>1.263212</td>\n      <td>3.148176</td>\n      <td>0.643088</td>\n      <td>5000</td>\n      <td>100</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8196</td>\n      <td>0.8266</td>\n      <td>0.8300</td>\n      <td>0.8324</td>\n      <td>0.8292</td>\n      <td>0.82756</td>\n      <td>0.004390</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18.812101</td>\n      <td>0.286187</td>\n      <td>2.982726</td>\n      <td>0.119216</td>\n      <td>20000</td>\n      <td>300</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8198</td>\n      <td>0.8208</td>\n      <td>0.8190</td>\n      <td>0.8304</td>\n      <td>0.8266</td>\n      <td>0.82332</td>\n      <td>0.004434</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19.829720</td>\n      <td>1.744731</td>\n      <td>4.132402</td>\n      <td>0.853231</td>\n      <td>5000</td>\n      <td>200</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8058</td>\n      <td>0.8192</td>\n      <td>0.8098</td>\n      <td>0.8188</td>\n      <td>0.8202</td>\n      <td>0.81476</td>\n      <td>0.005840</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>76.539661</td>\n      <td>1.091985</td>\n      <td>2.816238</td>\n      <td>0.083034</td>\n      <td>20000</td>\n      <td>200</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8356</td>\n      <td>0.8424</td>\n      <td>0.8380</td>\n      <td>0.8470</td>\n      <td>0.8416</td>\n      <td>0.84092</td>\n      <td>0.003910</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>57.310531</td>\n      <td>4.774374</td>\n      <td>2.995095</td>\n      <td>0.410694</td>\n      <td>5000</td>\n      <td>300</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8284</td>\n      <td>0.8336</td>\n      <td>0.8258</td>\n      <td>0.8388</td>\n      <td>0.8342</td>\n      <td>0.83216</td>\n      <td>0.004581</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>108.084574</td>\n      <td>0.442638</td>\n      <td>2.714026</td>\n      <td>0.085175</td>\n      <td>5000</td>\n      <td>300</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8304</td>\n      <td>0.8412</td>\n      <td>0.8390</td>\n      <td>0.8476</td>\n      <td>0.8400</td>\n      <td>0.83964</td>\n      <td>0.005508</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>74.050636</td>\n      <td>1.998914</td>\n      <td>2.662436</td>\n      <td>0.317836</td>\n      <td>5000</td>\n      <td>200</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8328</td>\n      <td>0.8424</td>\n      <td>0.8352</td>\n      <td>0.8464</td>\n      <td>0.8426</td>\n      <td>0.83988</td>\n      <td>0.005065</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>32.544724</td>\n      <td>0.656039</td>\n      <td>2.408186</td>\n      <td>0.249703</td>\n      <td>20000</td>\n      <td>100</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8270</td>\n      <td>0.8332</td>\n      <td>0.8330</td>\n      <td>0.8448</td>\n      <td>0.8396</td>\n      <td>0.83552</td>\n      <td>0.006117</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>42.586154</td>\n      <td>0.649467</td>\n      <td>3.254841</td>\n      <td>0.681108</td>\n      <td>15000</td>\n      <td>300</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8290</td>\n      <td>0.8344</td>\n      <td>0.8318</td>\n      <td>0.8394</td>\n      <td>0.8398</td>\n      <td>0.83488</td>\n      <td>0.004217</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>18.124797</td>\n      <td>1.233893</td>\n      <td>2.507843</td>\n      <td>0.421389</td>\n      <td>20000</td>\n      <td>100</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8240</td>\n      <td>0.8354</td>\n      <td>0.8214</td>\n      <td>0.8422</td>\n      <td>0.8264</td>\n      <td>0.82988</td>\n      <td>0.007757</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14.714802</td>\n      <td>1.141484</td>\n      <td>3.029146</td>\n      <td>0.375274</td>\n      <td>15000</td>\n      <td>200</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8114</td>\n      <td>0.8114</td>\n      <td>0.8214</td>\n      <td>0.8238</td>\n      <td>0.8262</td>\n      <td>0.81884</td>\n      <td>0.006262</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>21.462008</td>\n      <td>0.330464</td>\n      <td>2.636087</td>\n      <td>0.452202</td>\n      <td>15000</td>\n      <td>100</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8262</td>\n      <td>0.8334</td>\n      <td>0.8240</td>\n      <td>0.8384</td>\n      <td>0.8290</td>\n      <td>0.83020</td>\n      <td>0.005164</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>107.812964</td>\n      <td>1.901465</td>\n      <td>3.988276</td>\n      <td>0.963980</td>\n      <td>20000</td>\n      <td>300</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8354</td>\n      <td>0.8440</td>\n      <td>0.8394</td>\n      <td>0.8512</td>\n      <td>0.8468</td>\n      <td>0.84336</td>\n      <td>0.005527</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>120.473368</td>\n      <td>3.454322</td>\n      <td>3.530580</td>\n      <td>0.212565</td>\n      <td>10000</td>\n      <td>300</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8362</td>\n      <td>0.8444</td>\n      <td>0.8420</td>\n      <td>0.8468</td>\n      <td>0.8434</td>\n      <td>0.84256</td>\n      <td>0.003545</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>76.711362</td>\n      <td>1.045535</td>\n      <td>3.617515</td>\n      <td>0.506694</td>\n      <td>10000</td>\n      <td>200</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8312</td>\n      <td>0.8386</td>\n      <td>0.8376</td>\n      <td>0.8462</td>\n      <td>0.8480</td>\n      <td>0.84032</td>\n      <td>0.006117</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16.442223</td>\n      <td>2.119059</td>\n      <td>2.814499</td>\n      <td>0.599392</td>\n      <td>20000</td>\n      <td>200</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8144</td>\n      <td>0.8208</td>\n      <td>0.8112</td>\n      <td>0.8254</td>\n      <td>0.8182</td>\n      <td>0.81800</td>\n      <td>0.004936</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>17.500026</td>\n      <td>3.173084</td>\n      <td>2.306454</td>\n      <td>0.327360</td>\n      <td>10000</td>\n      <td>200</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8144</td>\n      <td>0.8210</td>\n      <td>0.8148</td>\n      <td>0.8248</td>\n      <td>0.8190</td>\n      <td>0.81880</td>\n      <td>0.003905</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>32.371416</td>\n      <td>0.477811</td>\n      <td>1.933712</td>\n      <td>0.091638</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8272</td>\n      <td>0.8334</td>\n      <td>0.8366</td>\n      <td>0.8404</td>\n      <td>0.8290</td>\n      <td>0.83332</td>\n      <td>0.004838</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>39.291709</td>\n      <td>1.279783</td>\n      <td>2.875189</td>\n      <td>0.148272</td>\n      <td>10000</td>\n      <td>300</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8266</td>\n      <td>0.8364</td>\n      <td>0.8318</td>\n      <td>0.8424</td>\n      <td>0.8424</td>\n      <td>0.83592</td>\n      <td>0.006133</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>17.072113</td>\n      <td>0.267165</td>\n      <td>2.538087</td>\n      <td>0.155290</td>\n      <td>10000</td>\n      <td>300</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8104</td>\n      <td>0.8206</td>\n      <td>0.8140</td>\n      <td>0.8228</td>\n      <td>0.8184</td>\n      <td>0.81724</td>\n      <td>0.004491</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>104.207083</td>\n      <td>1.551340</td>\n      <td>4.066934</td>\n      <td>0.365598</td>\n      <td>15000</td>\n      <td>300</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8382</td>\n      <td>0.8420</td>\n      <td>0.8420</td>\n      <td>0.8518</td>\n      <td>0.8452</td>\n      <td>0.84384</td>\n      <td>0.004556</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>38.174738</td>\n      <td>2.601185</td>\n      <td>3.336710</td>\n      <td>0.518688</td>\n      <td>10000</td>\n      <td>200</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8244</td>\n      <td>0.8322</td>\n      <td>0.8274</td>\n      <td>0.8424</td>\n      <td>0.8326</td>\n      <td>0.83180</td>\n      <td>0.006120</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>34.907445</td>\n      <td>6.594209</td>\n      <td>1.966354</td>\n      <td>0.588720</td>\n      <td>20000</td>\n      <td>300</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8302</td>\n      <td>0.8410</td>\n      <td>0.8300</td>\n      <td>0.8440</td>\n      <td>0.8382</td>\n      <td>0.83668</td>\n      <td>0.005677</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We will plot the score over the time taken to fit the matrix to visually represent the trade off in accuracy vs resources consumed for each set of hyperparameters\n",
    "X = df.mean_fit_time\n",
    "y = df.mean_test_score\n",
    "plt.scatter(X.index, y/X)\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('utility')\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "{'vectorizer__max_features': 15000,\n 'est__n_estimators': 200,\n 'est__max_depth': 5}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[np.argmax(y/X)].params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est__max_depth : 30\n",
      "est__n_estimators : 200\n",
      "vectorizer__max_features : 15000\n"
     ]
    }
   ],
   "source": [
    "for param in sorted(parameter_grid.keys()):\n",
    "    print(f\"{param} : {rscv.best_estimator_.get_params()[param]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above we display both the parameter set with the highest Utility, and the parameter set that produces the highest mean accuracy score. We measure utility as Score/Time, such that we pick not only the set that produces the best of hyperparameters that produces the best model, but also the one that takes the least time. We can compare that to the best over all hyper parameters and see that the the only difference between the two sets is that the max_depth is 5 when we maximize utility vs 30 when we are maxiziming accuracy without regard to the time take for the model to fit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "0.84112"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm = RecommenderSystem(trainLabeled, test)\n",
    "best_max_depth = rscv.best_estimator_.get_params()['est__max_depth']\n",
    "best_n_estimators = rscv.best_estimator_.get_params()['est__n_estimators']\n",
    "best_max_features = rscv.best_estimator_.get_params()['vectorizer__max_features']\n",
    "rm.vectorize(best_max_features)\n",
    "forest = RandomForestClassifier(max_depth=best_max_depth,n_estimators=best_n_estimators)\n",
    "rm.fit(forest).predict().score()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When we choose the best hyperparameter set we found and then predict based on the validation dataset, we determine that the baseline score for our tuned RandomForestClassifier is 84% accurate at binary classification for sentiment analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we will use the Keras library to build a rudimentary feed-forward neural network with just two regular Dense neural layers. We will use the sigmoid function for the output layer activation function, because this is a binary classification problem, and each answer should either be 0 or 1. The benefit of performing unsupervised learning, as we did early when we factored the original corpus of documents into two matrices (a vocabulary, and a tfidf sparse matrix), is that we can feed the same sparse matrix directly into our neural network without needing to use an embedding layer or an external embedding library.\n",
    "\n",
    "We will also be able to evaluate the effectiveness of even a very basic neural network compared to our RandomForestClassifier which required extensive hyperparameter tuning and preprocessing, at a significant cost of time, to implement.\n",
    "\n",
    "We will use the Adam optimization function, which is similar to Stochastic Gradient Descent, while being more computationally efficient and less memory intensive. We will use binary cross entropy loss, which is common for classification problems as a way of measuring error rate of predicted versus actual. We will additionally print out the accuracy of each epoch. We will use 3 epochs for our training, which means that each layer of the neural network will be trained on the entire corpus 3 times."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.3633 - accuracy: 0.8534 - val_loss: 0.2453 - val_accuracy: 0.8982\n",
      "Epoch 2/3\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1262 - accuracy: 0.9590 - val_loss: 0.2825 - val_accuracy: 0.8918\n",
      "Epoch 3/3\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9864 - val_loss: 0.3791 - val_accuracy: 0.8832\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x41430edd0>"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(rm.X_train.shape[1],))\n",
    "\n",
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\",name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"movie_reviews\")\n",
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(rm.X_train.todense(), rm.y_train, batch_size=64, epochs=3, validation_data=(rm.X_test.todense(),rm.y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[9.9977934e-01],\n       [1.5073504e-04],\n       [2.5365336e-04]], dtype=float32)"
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(rm.X_test[:3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"movie_reviews\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                1280064   \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1284289 (4.90 MB)\n",
      "Trainable params: 1284289 (4.90 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results and Analysis\n",
    "\n",
    "We can see that even an extremely naive implementation of the neural network achieves astounding results. With only 2 hidden layers of 64 neurons, we were still able to achieve over 89% prediction accuracy on the validation test set! That's a 5% improvement raw on our RandomForestClassifier at 84% accuracy on the validation set. The Netflix prize only required a 10% improvement! Additionally, our neural can be readily expanded to include additional layers of different types of neurons, including combinations of convolutional neurons, additional embeddings, different activations, and even recurrent neural network  frameworks.\n",
    "\n",
    "This illustrates the power and flexibility of preprocessing data and extracting features with unsupervised learning methods, as we can use both supervised and  deep learning methods on top of reduced dimension dataset with surprisingly effective results. An end-to-end model will likely use a combination of supervised, unsupervised, and deep learning, as well as preprocessing, cross validation, feature extraction, and other methods to empirically produce the most accurate and flexible model in a production enviornment\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
