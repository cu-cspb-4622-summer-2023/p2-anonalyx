{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-15T01:53:30.207565Z",
     "start_time": "2023-08-15T01:53:30.205778Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.losses\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project Topic\n",
    "\n",
    "\n",
    "Explanation: Sentiment analysis is one of the crowning achievements of recent advances in machine learning. In its most naive form, sentiment analysis is a simple binary classification with two possible label outputs, calculated as a function of an input string. In the case that we will explore, the input string is a single movie review, and the corpus of documents is all of the full text movie reviews in the dataset. The basic strategy for sentiment analysis includes drawing inferences and making predictions based on the relative importance and prominence of a word within a sequence or given document against the corpus of all documents. In this report, we will be utilizing unsupervised, supervised, and deep learning methods to estimate sentiment analysis on a corpus of documents.\n",
    "\n",
    "Our strategy in this report will be to use the tfidf vectorizer from sklearn to create a vocabulary and sparse matrix for each document. Then we will build a supervised model with the Random Forest Classifier, using Randomized Search CV to tune the hyperparameters for both the vectorizer and the Random Forest Classifier as a benchmark. Finally, we will build a multilayer neural network with Keras, that uses our sparse matrix and vocabulary as input, and determines the appropriate label as an output.\n",
    "Motivation: My motivation is to wield the full spectrum of techniques across unsupervised, supervised, and deep learning that we have learned this semester in a cohesive end-to-end model, and to compare the results between these approaches."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data\n",
    "Source: Kaggle.com \"Bag of Words Meets Bags of Popcorn\" https://www.kaggle.com/competitions/word2vec-nlp-tutorial/data\n",
    "Description: The Bag of Words Meets Bags of Popcorn Dataset is the dataset used in an NLP tutorial on Kaggle.com. I have not previously viewed or completed this tutorial and do not intend to use the techniques and methods described in the tutorial in the completion of my project.\n",
    "\n",
    "The dataset includes three features \"id\" (categorical), \"sentiment\" (numerical), and \"review\" (categorical). There are 75,000 total observations (25,000 train observations, and 50,000 test observations) in the dataset. The train observations are labeled with sentiment 1.0 or 0.0, where a review was scored either >= 7 or < 7 respectively. There are no null values, in the train dataset.\n",
    "\n",
    "Given we do not have the labels for the test dataset, we will have to use a portion of the train data set for validation purposes, and we will not be able to fully evaluate the efficacy of our model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 75000 entries, \"5814_8\" to 35270_0\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sentiment  25000 non-null  float64\n",
      " 1   review     75000 non-null  object \n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "class RecommenderSystem:\n",
    "    def __init__(self, train, test):\n",
    "        self.ntrain = len(train)\n",
    "        self.ntest = len(test)\n",
    "        self.X = pd.concat([trainLabeled, test]).dropna(how='all')\n",
    "        self.test = np.asarray(self.X[self.ntrain:])\n",
    "\n",
    "    def vectorize(self, max_features):\n",
    "        vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "        Xtfidf = vectorizer.fit_transform(self.X['review'])\n",
    "        self.vocab = np.asarray(vectorizer.get_feature_names_out())\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(Xtfidf[:self.ntrain], np.asarray(self.X[:self.ntrain]['sentiment']))\n",
    "        return self\n",
    "    def fit(self, model):\n",
    "        self.model = model\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self):\n",
    "        self.yp = self.model.predict(self.X_test)\n",
    "        return self\n",
    "\n",
    "    def score(self):\n",
    "        return accuracy_score(self.y_test, self.yp)\n",
    "\n",
    "trainLabeled = pd.read_csv('./data/labeledTrainData.tsv', sep='\\t', header=0, quoting=3).set_index('id')\n",
    "test = pd.read_csv('./data/unlabeledTrainData.tsv', sep='\\t', header=0, quoting=3).set_index('id').drop('Unnamed: 2',axis=1)\n",
    "\n",
    "rm.X.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning and EDA\n",
    "Explanation of how and why cleaning is performed:\n",
    "\n",
    "The cleaning that we need to do on this dataset is limited to the cleaning and parsing of strings, and resulting transformation into a sparse matrix for input into subsequent models. Looking at the reviews, we can see that the text is ascii, however, we will need to make sure that all of the words are lowercase, that all punctuation and special characters are removed, that all stop words are eliminated.\n",
    "\n",
    "The sklearn vectorizers will perform these transformations for us automatically when we pass our full dataset to the fit_transform function. TFIDF does not remove stop words, however, by setting max_features at any reasonable threshold, we will eliminate those tokens which are most common to all documents in the corpus and thus, least meaningful, implicitly eliminating the stop words for us.\n",
    "\n",
    "To transform the data into a sparse matrix, we are going to use a textvectorizer that calculates the term frequency, inverse document frequency (TFIDF) of each word in each document. This will produce a vocabulary for us that consists of a vector of length (max_features) where each element of the vector corresponds with a word in our vocabulary. Our vocabulary will be derived from the full set of all reviews (training and test). As we learned in previous assignments, we can derive our vocabulary from the entire corpus of documents, without biasing our model. This is because our TFIDF vectorizer is not aware of the labels associated with each observation, and is merely deriving the relationship between words and documents in the corpus.\n",
    "\n",
    "We will chose TFIDF over a basic CountVectorizer, given the basic objective of sentiment analysis is identifying the magnitude and direction of each word as it relates to the overall sentiment of the document. A simple word count would be too likely to include words that are frequently used but have low meaning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n                ('est', RandomForestClassifier())])",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n                (&#x27;est&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n                (&#x27;est&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", TfidfVectorizer()),\n",
    "        (\"est\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomizedSearchCV(estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n                                             ('est',\n                                              RandomForestClassifier())]),\n                   n_iter=25, n_jobs=-1,\n                   param_distributions={'est__max_depth': (5, 15, 30),\n                                        'est__n_estimators': (100, 200, 300),\n                                        'vectorizer__max_features': (5000,\n                                                                     10000,\n                                                                     15000,\n                                                                     20000)},\n                   verbose=1)",
      "text/html": "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n                                             (&#x27;est&#x27;,\n                                              RandomForestClassifier())]),\n                   n_iter=25, n_jobs=-1,\n                   param_distributions={&#x27;est__max_depth&#x27;: (5, 15, 30),\n                                        &#x27;est__n_estimators&#x27;: (100, 200, 300),\n                                        &#x27;vectorizer__max_features&#x27;: (5000,\n                                                                     10000,\n                                                                     15000,\n                                                                     20000)},\n                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n                                             (&#x27;est&#x27;,\n                                              RandomForestClassifier())]),\n                   n_iter=25, n_jobs=-1,\n                   param_distributions={&#x27;est__max_depth&#x27;: (5, 15, 30),\n                                        &#x27;est__n_estimators&#x27;: (100, 200, 300),\n                                        &#x27;vectorizer__max_features&#x27;: (5000,\n                                                                     10000,\n                                                                     15000,\n                                                                     20000)},\n                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n                (&#x27;est&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_grid = {\n",
    "    \"vectorizer__max_features\": (5000, 10000,15000,20000),\n",
    "    \"est__n_estimators\": ( 100, 200, 300),\n",
    "    \"est__max_depth\": (5, 15, 30),\n",
    "}\n",
    "rscv = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=parameter_grid,\n",
    "    n_iter=25,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "rscv.fit(trainLabeled.review, trainLabeled.sentiment)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rscv.cv_results_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.mean_fit_time\n",
    "y = df.mean_test_score\n",
    "plt.scatter(X.index, y/X)\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "{'vectorizer__max_features': 15000,\n 'est__n_estimators': 100,\n 'est__max_depth': 5}"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[np.argmax(y/X)].params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time   \n0        5.803449      0.510379         0.618816        0.038915  \\\n1        9.864098      0.870843         0.734909        0.046988   \n2        5.104265      0.144178         0.745544        0.051471   \n3       12.319468      0.812783         0.896772        0.053672   \n4        6.815732      0.148851         0.815252        0.065269   \n5       19.782057      1.491703         0.879936        0.035930   \n6       12.509974      0.756201         0.733105        0.043120   \n7       28.931669      2.169771         0.965643        0.089309   \n8        5.723303      0.259110         0.762385        0.055897   \n9        3.886933      0.082076         0.633085        0.034436   \n10       5.964763      0.411657         0.825570        0.060196   \n11      19.819143      0.410539         0.827833        0.040792   \n12       8.785811      0.635332         0.745415        0.019952   \n13       4.010532      0.292951         0.737954        0.044975   \n14       4.232604      0.098095         0.651996        0.033181   \n15       3.773210      0.099237         0.691128        0.049475   \n16      11.896594      0.669280         0.733394        0.074647   \n17       6.011425      0.164764         0.694511        0.096759   \n18      17.177620      0.976457         0.866215        0.125271   \n19       9.399732      0.114492         0.808446        0.022932   \n20       3.477115      0.101473         0.704747        0.070456   \n21      24.317086      0.248317         1.022065        0.103273   \n22      14.563399      1.611706         0.897614        0.108304   \n23      33.862753      2.986522         0.872907        0.073368   \n24      25.635327      2.387563         0.758552        0.101308   \n\n   param_vectorizer__max_features param_est__n_estimators   \n0                           10000                     100  \\\n1                           10000                     200   \n2                            5000                     200   \n3                           20000                     300   \n4                            5000                     300   \n5                           15000                     200   \n6                            5000                     200   \n7                           10000                     300   \n8                           20000                     100   \n9                            5000                     100   \n10                          10000                     300   \n11                          20000                     200   \n12                          15000                     200   \n13                          20000                     200   \n14                          10000                     200   \n15                          15000                     200   \n16                          10000                     100   \n17                          15000                     100   \n18                           5000                     300   \n19                          20000                     200   \n20                          15000                     100   \n21                           5000                     200   \n22                          15000                     100   \n23                          20000                     300   \n24                          10000                     200   \n\n   param_est__max_depth                                             params   \n0                    15  {'vectorizer__max_features': 10000, 'est__n_es...  \\\n1                    15  {'vectorizer__max_features': 10000, 'est__n_es...   \n2                     5  {'vectorizer__max_features': 5000, 'est__n_est...   \n3                    15  {'vectorizer__max_features': 20000, 'est__n_es...   \n4                     5  {'vectorizer__max_features': 5000, 'est__n_est...   \n5                    30  {'vectorizer__max_features': 15000, 'est__n_es...   \n6                    15  {'vectorizer__max_features': 5000, 'est__n_est...   \n7                    30  {'vectorizer__max_features': 10000, 'est__n_es...   \n8                    15  {'vectorizer__max_features': 20000, 'est__n_es...   \n9                     5  {'vectorizer__max_features': 5000, 'est__n_est...   \n10                    5  {'vectorizer__max_features': 10000, 'est__n_es...   \n11                   30  {'vectorizer__max_features': 20000, 'est__n_es...   \n12                   15  {'vectorizer__max_features': 15000, 'est__n_es...   \n13                    5  {'vectorizer__max_features': 20000, 'est__n_es...   \n14                    5  {'vectorizer__max_features': 10000, 'est__n_es...   \n15                    5  {'vectorizer__max_features': 15000, 'est__n_es...   \n16                   30  {'vectorizer__max_features': 10000, 'est__n_es...   \n17                   15  {'vectorizer__max_features': 15000, 'est__n_es...   \n18                   15  {'vectorizer__max_features': 5000, 'est__n_est...   \n19                   15  {'vectorizer__max_features': 20000, 'est__n_es...   \n20                    5  {'vectorizer__max_features': 15000, 'est__n_es...   \n21                   30  {'vectorizer__max_features': 5000, 'est__n_est...   \n22                   30  {'vectorizer__max_features': 15000, 'est__n_es...   \n23                   30  {'vectorizer__max_features': 20000, 'est__n_es...   \n24                   30  {'vectorizer__max_features': 10000, 'est__n_es...   \n\n    split0_test_score  split1_test_score  split2_test_score   \n0              0.8234             0.8338             0.8248  \\\n1              0.8280             0.8338             0.8278   \n2              0.8096             0.8170             0.8112   \n3              0.8288             0.8352             0.8352   \n4              0.8146             0.8154             0.8154   \n5              0.8316             0.8434             0.8378   \n6              0.8258             0.8316             0.8274   \n7              0.8372             0.8436             0.8436   \n8              0.8232             0.8322             0.8272   \n9              0.8126             0.8086             0.8136   \n10             0.8128             0.8240             0.8154   \n11             0.8336             0.8396             0.8426   \n12             0.8262             0.8338             0.8282   \n13             0.8024             0.8166             0.8152   \n14             0.8150             0.8220             0.8138   \n15             0.8154             0.8132             0.8146   \n16             0.8262             0.8370             0.8394   \n17             0.8266             0.8248             0.8290   \n18             0.8270             0.8306             0.8290   \n19             0.8260             0.8406             0.8344   \n20             0.8136             0.8146             0.8106   \n21             0.8304             0.8376             0.8410   \n22             0.8328             0.8382             0.8336   \n23             0.8424             0.8460             0.8418   \n24             0.8384             0.8432             0.8388   \n\n    split3_test_score  split4_test_score  mean_test_score  std_test_score   \n0              0.8300             0.8286          0.82812        0.003724  \\\n1              0.8342             0.8366          0.83208        0.003545   \n2              0.8180             0.8168          0.81452        0.003426   \n3              0.8394             0.8398          0.83568        0.003965   \n4              0.8248             0.8242          0.81888        0.004602   \n5              0.8468             0.8482          0.84156        0.006136   \n6              0.8412             0.8322          0.83164        0.005363   \n7              0.8466             0.8460          0.84340        0.003332   \n8              0.8342             0.8282          0.82900        0.003868   \n9              0.8172             0.8074          0.81188        0.003539   \n10             0.8224             0.8236          0.81964        0.004628   \n11             0.8484             0.8400          0.84084        0.004794   \n12             0.8348             0.8338          0.83136        0.003474   \n13             0.8252             0.8208          0.81604        0.007663   \n14             0.8146             0.8222          0.81752        0.003760   \n15             0.8206             0.8224          0.81724        0.003594   \n16             0.8438             0.8378          0.83684        0.005816   \n17             0.8328             0.8296          0.82856        0.002729   \n18             0.8396             0.8378          0.83280        0.004983   \n19             0.8380             0.8338          0.83456        0.004944   \n20             0.8216             0.8116          0.81440        0.003868   \n21             0.8478             0.8412          0.83960        0.005664   \n22             0.8446             0.8412          0.83808        0.004477   \n23             0.8524             0.8444          0.84540        0.003803   \n24             0.8530             0.8428          0.84324        0.005265   \n\n    rank_test_score  \n0                17  \n1                12  \n2                23  \n3                 9  \n4                19  \n5                 4  \n6                13  \n7                 2  \n8                15  \n9                25  \n10               18  \n11                5  \n12               14  \n13               22  \n14               20  \n15               21  \n16                8  \n17               16  \n18               11  \n19               10  \n20               24  \n21                6  \n22                7  \n23                1  \n24                3  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_vectorizer__max_features</th>\n      <th>param_est__n_estimators</th>\n      <th>param_est__max_depth</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.803449</td>\n      <td>0.510379</td>\n      <td>0.618816</td>\n      <td>0.038915</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8234</td>\n      <td>0.8338</td>\n      <td>0.8248</td>\n      <td>0.8300</td>\n      <td>0.8286</td>\n      <td>0.82812</td>\n      <td>0.003724</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.864098</td>\n      <td>0.870843</td>\n      <td>0.734909</td>\n      <td>0.046988</td>\n      <td>10000</td>\n      <td>200</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8280</td>\n      <td>0.8338</td>\n      <td>0.8278</td>\n      <td>0.8342</td>\n      <td>0.8366</td>\n      <td>0.83208</td>\n      <td>0.003545</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.104265</td>\n      <td>0.144178</td>\n      <td>0.745544</td>\n      <td>0.051471</td>\n      <td>5000</td>\n      <td>200</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8096</td>\n      <td>0.8170</td>\n      <td>0.8112</td>\n      <td>0.8180</td>\n      <td>0.8168</td>\n      <td>0.81452</td>\n      <td>0.003426</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12.319468</td>\n      <td>0.812783</td>\n      <td>0.896772</td>\n      <td>0.053672</td>\n      <td>20000</td>\n      <td>300</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8288</td>\n      <td>0.8352</td>\n      <td>0.8352</td>\n      <td>0.8394</td>\n      <td>0.8398</td>\n      <td>0.83568</td>\n      <td>0.003965</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.815732</td>\n      <td>0.148851</td>\n      <td>0.815252</td>\n      <td>0.065269</td>\n      <td>5000</td>\n      <td>300</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8146</td>\n      <td>0.8154</td>\n      <td>0.8154</td>\n      <td>0.8248</td>\n      <td>0.8242</td>\n      <td>0.81888</td>\n      <td>0.004602</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>19.782057</td>\n      <td>1.491703</td>\n      <td>0.879936</td>\n      <td>0.035930</td>\n      <td>15000</td>\n      <td>200</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8316</td>\n      <td>0.8434</td>\n      <td>0.8378</td>\n      <td>0.8468</td>\n      <td>0.8482</td>\n      <td>0.84156</td>\n      <td>0.006136</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>12.509974</td>\n      <td>0.756201</td>\n      <td>0.733105</td>\n      <td>0.043120</td>\n      <td>5000</td>\n      <td>200</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8258</td>\n      <td>0.8316</td>\n      <td>0.8274</td>\n      <td>0.8412</td>\n      <td>0.8322</td>\n      <td>0.83164</td>\n      <td>0.005363</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>28.931669</td>\n      <td>2.169771</td>\n      <td>0.965643</td>\n      <td>0.089309</td>\n      <td>10000</td>\n      <td>300</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8372</td>\n      <td>0.8436</td>\n      <td>0.8436</td>\n      <td>0.8466</td>\n      <td>0.8460</td>\n      <td>0.84340</td>\n      <td>0.003332</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5.723303</td>\n      <td>0.259110</td>\n      <td>0.762385</td>\n      <td>0.055897</td>\n      <td>20000</td>\n      <td>100</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8232</td>\n      <td>0.8322</td>\n      <td>0.8272</td>\n      <td>0.8342</td>\n      <td>0.8282</td>\n      <td>0.82900</td>\n      <td>0.003868</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.886933</td>\n      <td>0.082076</td>\n      <td>0.633085</td>\n      <td>0.034436</td>\n      <td>5000</td>\n      <td>100</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8126</td>\n      <td>0.8086</td>\n      <td>0.8136</td>\n      <td>0.8172</td>\n      <td>0.8074</td>\n      <td>0.81188</td>\n      <td>0.003539</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5.964763</td>\n      <td>0.411657</td>\n      <td>0.825570</td>\n      <td>0.060196</td>\n      <td>10000</td>\n      <td>300</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8128</td>\n      <td>0.8240</td>\n      <td>0.8154</td>\n      <td>0.8224</td>\n      <td>0.8236</td>\n      <td>0.81964</td>\n      <td>0.004628</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>19.819143</td>\n      <td>0.410539</td>\n      <td>0.827833</td>\n      <td>0.040792</td>\n      <td>20000</td>\n      <td>200</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8336</td>\n      <td>0.8396</td>\n      <td>0.8426</td>\n      <td>0.8484</td>\n      <td>0.8400</td>\n      <td>0.84084</td>\n      <td>0.004794</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>8.785811</td>\n      <td>0.635332</td>\n      <td>0.745415</td>\n      <td>0.019952</td>\n      <td>15000</td>\n      <td>200</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8262</td>\n      <td>0.8338</td>\n      <td>0.8282</td>\n      <td>0.8348</td>\n      <td>0.8338</td>\n      <td>0.83136</td>\n      <td>0.003474</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4.010532</td>\n      <td>0.292951</td>\n      <td>0.737954</td>\n      <td>0.044975</td>\n      <td>20000</td>\n      <td>200</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8024</td>\n      <td>0.8166</td>\n      <td>0.8152</td>\n      <td>0.8252</td>\n      <td>0.8208</td>\n      <td>0.81604</td>\n      <td>0.007663</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4.232604</td>\n      <td>0.098095</td>\n      <td>0.651996</td>\n      <td>0.033181</td>\n      <td>10000</td>\n      <td>200</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8150</td>\n      <td>0.8220</td>\n      <td>0.8138</td>\n      <td>0.8146</td>\n      <td>0.8222</td>\n      <td>0.81752</td>\n      <td>0.003760</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>3.773210</td>\n      <td>0.099237</td>\n      <td>0.691128</td>\n      <td>0.049475</td>\n      <td>15000</td>\n      <td>200</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8154</td>\n      <td>0.8132</td>\n      <td>0.8146</td>\n      <td>0.8206</td>\n      <td>0.8224</td>\n      <td>0.81724</td>\n      <td>0.003594</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>11.896594</td>\n      <td>0.669280</td>\n      <td>0.733394</td>\n      <td>0.074647</td>\n      <td>10000</td>\n      <td>100</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8262</td>\n      <td>0.8370</td>\n      <td>0.8394</td>\n      <td>0.8438</td>\n      <td>0.8378</td>\n      <td>0.83684</td>\n      <td>0.005816</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>6.011425</td>\n      <td>0.164764</td>\n      <td>0.694511</td>\n      <td>0.096759</td>\n      <td>15000</td>\n      <td>100</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8266</td>\n      <td>0.8248</td>\n      <td>0.8290</td>\n      <td>0.8328</td>\n      <td>0.8296</td>\n      <td>0.82856</td>\n      <td>0.002729</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>17.177620</td>\n      <td>0.976457</td>\n      <td>0.866215</td>\n      <td>0.125271</td>\n      <td>5000</td>\n      <td>300</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8270</td>\n      <td>0.8306</td>\n      <td>0.8290</td>\n      <td>0.8396</td>\n      <td>0.8378</td>\n      <td>0.83280</td>\n      <td>0.004983</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>9.399732</td>\n      <td>0.114492</td>\n      <td>0.808446</td>\n      <td>0.022932</td>\n      <td>20000</td>\n      <td>200</td>\n      <td>15</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8260</td>\n      <td>0.8406</td>\n      <td>0.8344</td>\n      <td>0.8380</td>\n      <td>0.8338</td>\n      <td>0.83456</td>\n      <td>0.004944</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>3.477115</td>\n      <td>0.101473</td>\n      <td>0.704747</td>\n      <td>0.070456</td>\n      <td>15000</td>\n      <td>100</td>\n      <td>5</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8136</td>\n      <td>0.8146</td>\n      <td>0.8106</td>\n      <td>0.8216</td>\n      <td>0.8116</td>\n      <td>0.81440</td>\n      <td>0.003868</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>24.317086</td>\n      <td>0.248317</td>\n      <td>1.022065</td>\n      <td>0.103273</td>\n      <td>5000</td>\n      <td>200</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 5000, 'est__n_est...</td>\n      <td>0.8304</td>\n      <td>0.8376</td>\n      <td>0.8410</td>\n      <td>0.8478</td>\n      <td>0.8412</td>\n      <td>0.83960</td>\n      <td>0.005664</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>14.563399</td>\n      <td>1.611706</td>\n      <td>0.897614</td>\n      <td>0.108304</td>\n      <td>15000</td>\n      <td>100</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 15000, 'est__n_es...</td>\n      <td>0.8328</td>\n      <td>0.8382</td>\n      <td>0.8336</td>\n      <td>0.8446</td>\n      <td>0.8412</td>\n      <td>0.83808</td>\n      <td>0.004477</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>33.862753</td>\n      <td>2.986522</td>\n      <td>0.872907</td>\n      <td>0.073368</td>\n      <td>20000</td>\n      <td>300</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 20000, 'est__n_es...</td>\n      <td>0.8424</td>\n      <td>0.8460</td>\n      <td>0.8418</td>\n      <td>0.8524</td>\n      <td>0.8444</td>\n      <td>0.84540</td>\n      <td>0.003803</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25.635327</td>\n      <td>2.387563</td>\n      <td>0.758552</td>\n      <td>0.101308</td>\n      <td>10000</td>\n      <td>200</td>\n      <td>30</td>\n      <td>{'vectorizer__max_features': 10000, 'est__n_es...</td>\n      <td>0.8384</td>\n      <td>0.8432</td>\n      <td>0.8388</td>\n      <td>0.8530</td>\n      <td>0.8428</td>\n      <td>0.84324</td>\n      <td>0.005265</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est__max_depth : 30\n",
      "est__n_estimators : 300\n",
      "vectorizer__max_features : 20000\n"
     ]
    }
   ],
   "source": [
    "for param in sorted(parameter_grid.keys()):\n",
    "    print(f\"{param} : {rscv.best_estimator_.get_params()[param]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "data": {
      "text/plain": "0.84496"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm = RecommenderSystem(trainLabeled, test)\n",
    "best_max_depth = rscv.best_estimator_.get_params()['est__max_depth']\n",
    "best_n_estimators = rscv.best_estimator_.get_params()['est__n_estimators']\n",
    "best_max_features = rscv.best_estimator_.get_params()['vectorizer__max_features']\n",
    "rm.vectorize(best_max_features)\n",
    "forest = RandomForestClassifier(max_depth=best_max_depth,n_estimators=best_n_estimators)\n",
    "rm.fit(forest).predict().score()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.3633 - accuracy: 0.8534 - val_loss: 0.2453 - val_accuracy: 0.8982\n",
      "Epoch 2/3\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1262 - accuracy: 0.9590 - val_loss: 0.2825 - val_accuracy: 0.8918\n",
      "Epoch 3/3\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9864 - val_loss: 0.3791 - val_accuracy: 0.8832\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x41430edd0>"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(rm.X_train.shape[1],))\n",
    "\n",
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1,activation=\"sigmoid\",name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"movie_reviews\")\n",
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(rm.X_train.todense(), rm.y_train, batch_size=64, epochs=3, validation_data=(rm.X_test.todense(),rm.y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[9.9977934e-01],\n       [1.5073504e-04],\n       [2.5365336e-04]], dtype=float32)"
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(rm.X_test[:3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"movie_reviews\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                1280064   \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1284289 (4.90 MB)\n",
      "Trainable params: 1284289 (4.90 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tabulated Examples\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualizations\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusions and Discussions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model building/ Model Choice"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training\n",
    "Training procedure:\n",
    "Hyperparameter Tuning:\n",
    "Train/Test Performance:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results and Analysis\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison of Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discussion and Conclusion on final results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T21:47:10.898446Z",
     "start_time": "2023-08-14T21:47:10.897321Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
